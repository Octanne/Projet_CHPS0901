{
  "_cqa_text_report":
    {
      "_objects":
        {
          "image_vec_align":
            {
              "type": "image",
              "format": "url",
              "data": "../images/cqa/vec_align.svg",
              "size":
                {
                  "x": 500
                }
            },
          "image_1x64_512":
            {
              "type": "image",
              "format": "url",
              "data": "../images/cqa/1x64_512.svg",
              "size":
                {
                  "x": 500
                }
            },
          "image_1x32_128":
            {
              "type": "image",
              "format": "url",
              "data": "../images/cqa/1x32_128.svg",
              "size":
                {
                  "x": 500
                }
            },
          "image_4x32_256":
            {
              "type": "image",
              "format": "url",
              "data": "../images/cqa/4x32_256.svg",
              "size":
                {
                  "x": 500
                }
            },
          "image_1x64_128":
            {
              "type": "image",
              "format": "url",
              "data": "../images/cqa/1x64_128.svg",
              "size":
                {
                  "x": 500
                }
            },
          "image_4x32_512":
            {
              "type": "image",
              "format": "url",
              "data": "../images/cqa/4x32_512.svg",
              "size":
                {
                  "x": 500
                }
            },
          "image_8x32_512":
            {
              "type": "image",
              "format": "url",
              "data": "../images/cqa/8x32_512.svg",
              "size":
                {
                  "x": 500
                }
            },
          "image_1x32_256":
            {
              "type": "image",
              "format": "url",
              "data": "../images/cqa/1x32_256.svg",
              "size":
                {
                  "x": 500
                }
            },
          "image_2x64_512":
            {
              "type": "image",
              "format": "url",
              "data": "../images/cqa/2x64_512.svg",
              "size":
                {
                  "x": 500
                }
            },
          "image_2x64_256":
            {
              "type": "image",
              "format": "url",
              "data": "../images/cqa/2x64_256.svg",
              "size":
                {
                  "x": 500
                }
            },
          "image_1x64_256":
            {
              "type": "image",
              "format": "url",
              "data": "../images/cqa/1x64_256.svg",
              "size":
                {
                  "x": 500
                }
            },
          "image_1x32_512":
            {
              "type": "image",
              "format": "url",
              "data": "../images/cqa/1x32_512.svg",
              "size":
                {
                  "x": 500
                }
            },
          "image_4x64_512":
            {
              "type": "image",
              "format": "url",
              "data": "../images/cqa/4x64_512.svg",
              "size":
                {
                  "x": 500
                }
            },
          "image_row_maj":
            {
              "type": "image",
              "format": "url",
              "data": "../images/cqa/row_maj.svg",
              "size":
                {
                  "x": 500
                }
            },
          "image_col_maj":
            {
              "type": "image",
              "format": "url",
              "data": "../images/cqa/col_maj.svg",
              "size":
                {
                  "x": 500
                }
            }
        },
      "AVG":
        {
          "hint":
            [
              {
                "title": "Type of elements and instruction set",
                "txt": "No instructions are processing arithmetic or math operations on FP elements. This function is probably writing/copying data or processing integer elements."
              },
              {
                "title": "Matching between your function (in the source code) and the binary function",
                "txt": "The binary function does not contain any FP arithmetical operations.\nThe binary function is storing 8 bytes."
              }
            ],
          "expert":
            [
              {
                "title": "General properties",
                "txt": "nb instructions    : 2\nnb uops            : 2\nloop length        : 6\nused x86 registers : 1\nused mmx registers : 0\nused xmm registers : 1\nused ymm registers : 0\nused zmm registers : 0\nnb stack references: 0\n"
              },
              {
                "title": "Front-end",
                "txt": "MACRO FUSION NOT POSSIBLE\nFIT IN UOP CACHE\nmicro-operation queue: 0.33 cycles\nfront end            : 0.33 cycles\n"
              },
              {
                "title": "Back-end",
                "txt": "       | ALU0/BRU0 | ALU1 | ALU2 | ALU3/BRU1 | AGU0 | AGU1 | AGU2 | FP0  | FP1  | FP2  | FP3\n---------------------------------------------------------------------------------------------\nuops   | 0.50      | 0.00 | 0.00 | 0.50      | 0.33 | 0.33 | 0.33 | 0.00 | 0.00 | 1.00 | 0.00\ncycles | 0.50      | 0.00 | 0.00 | 0.50      | 0.33 | 0.33 | 0.33 | 0.00 | 0.00 | 1.00 | 0.00\n\nExecution ports to units layout:\n - ALU0/BRU0: ALU, BRU\n - ALU1: ALU\n - ALU2: ALU\n - ALU3/BRU1: ALU, BRU\n - AGU0 (256 bits): store address, load\n - AGU1 (256 bits): store address, load\n - AGU2: store address\n - FP0 (256 bits): VPU\n - FP1 (256 bits): VPU\n - FP2 (256 bits): VPU, FP store data\n - FP3 (256 bits): VPU, DIV/SQRT\n\nCycles executing div or sqrt instructions: NA\nCycles loading/storing data              : 1.00\n"
              },
              {
                "title": "Cycles summary",
                "txt": "Front-end : 0.33\nDispatch  : 1.00\nOverall L1: 1.00\n"
              },
              {
                "title": "Vectorization ratios",
                "txt": "all     : 0%\nload    : NA (no load vectorizable/vectorized instructions)\nstore   : 0%\nmul     : NA (no mul vectorizable/vectorized instructions)\nadd-sub : NA (no add-sub vectorizable/vectorized instructions)\nfma     : NA (no fma vectorizable/vectorized instructions)\ndiv/sqrt: NA (no div/sqrt vectorizable/vectorized instructions)\nother   : NA (no other vectorizable/vectorized instructions)\n"
              },
              {
                "title": "Vector efficiency ratios",
                "txt": "all     : 25%\nload    : NA (no load vectorizable/vectorized instructions)\nstore   : 25%\nmul     : NA (no mul vectorizable/vectorized instructions)\nadd-sub : NA (no add-sub vectorizable/vectorized instructions)\nfma     : NA (no fma vectorizable/vectorized instructions)\ndiv/sqrt: NA (no div/sqrt vectorizable/vectorized instructions)\nother   : NA (no other vectorizable/vectorized instructions)\n"
              },
              {
                "title": "Cycles and memory resources usage",
                "txt": "Assuming all data fit into the L1 cache, each call to the function takes 1.00 cycles. At this rate:\n - 25% of peak store performance is reached (8.00 out of 32.00 bytes stored per cycle (GB/s @ 1GHz))\n"
              },
              {
                "title": "Front-end bottlenecks",
                "txt": "Found no such bottlenecks."
              },
              {
                "title": "ASM code",
                "txt": "In the binary file, the address of the function is: 3bf40\n\nInstruction             | Nb FU | ALU0/BRU0 | ALU1 | ALU2 | ALU3/BRU1 | AGU0 | AGU1 | AGU2 | FP0 | FP1 | FP2 | FP3 | Latency | Recip. throughput | Vectorization\n----------------------------------------------------------------------------------------------------------------------------------------------------------------\nVMOVSD %XMM0,0x10(%RDI) | 1     | 0         | 0    | 0    | 0         | 0.33 | 0.33 | 0.33 | 0   | 0   | 1   | 0   | 1       | 1                 | scal (25.0%)\nRET                     | 1     | 0.50      | 0    | 0    | 0.50      | 0    | 0    | 0    | 0   | 0   | 0   | 0   | 1       | 0.50              | N/A\n"
              }
            ],
          "header":
            [
            "0% of peak computational performance is used (0.00 out of 48.00 FLOP per cycle (GFLOPS @ 1GHz))"
            ],
          "brief":
            [

            ],
          "gain":
            [
              {
                "workaround": " - Try another compiler or update/tune your current one\n - Make array accesses unit-stride:\n  * If your function streams arrays of structures (AoS), try to use structures of arrays instead (SoA):\nfor(i) a[i].x = b[i].x; (slow, non stride 1) => for(i) a.x[i] = b.x[i]; (fast, stride 1)\n",
                "details": "All SSE/AVX instructions are used in scalar version (process only one data element in vector registers).\nSince your execution units are vector units, only a vectorized function can use their full power.\n",
                "title": "Vectorization",
                "txt": "Your function is not vectorized.\n4 data elements could be processed at once in vector registers.\nBy vectorizing your function, you can lower the cost of an iteration from 1.00 to 0.25 cycles (4.00x speedup)."
              },
              {
                "title": "Execution units bottlenecks",
                "txt": "Found no such bottlenecks but see expert reports for more complex bottlenecks."
              }
            ],
          "potential":
            [

            ]
        },
      "paths":
        [
          {
            "hint":
              [
                {
                  "title": "Type of elements and instruction set",
                  "txt": "No instructions are processing arithmetic or math operations on FP elements. This function is probably writing/copying data or processing integer elements."
                },
                {
                  "title": "Matching between your function (in the source code) and the binary function",
                  "txt": "The binary function does not contain any FP arithmetical operations.\nThe binary function is storing 8 bytes."
                }
              ],
            "expert":
              [
                {
                  "title": "General properties",
                  "txt": "nb instructions    : 2\nnb uops            : 2\nloop length        : 6\nused x86 registers : 1\nused mmx registers : 0\nused xmm registers : 1\nused ymm registers : 0\nused zmm registers : 0\nnb stack references: 0\n"
                },
                {
                  "title": "Front-end",
                  "txt": "MACRO FUSION NOT POSSIBLE\nFIT IN UOP CACHE\nmicro-operation queue: 0.33 cycles\nfront end            : 0.33 cycles\n"
                },
                {
                  "title": "Back-end",
                  "txt": "       | ALU0/BRU0 | ALU1 | ALU2 | ALU3/BRU1 | AGU0 | AGU1 | AGU2 | FP0  | FP1  | FP2  | FP3\n---------------------------------------------------------------------------------------------\nuops   | 0.50      | 0.00 | 0.00 | 0.50      | 0.33 | 0.33 | 0.33 | 0.00 | 0.00 | 1.00 | 0.00\ncycles | 0.50      | 0.00 | 0.00 | 0.50      | 0.33 | 0.33 | 0.33 | 0.00 | 0.00 | 1.00 | 0.00\n\nExecution ports to units layout:\n - ALU0/BRU0: ALU, BRU\n - ALU1: ALU\n - ALU2: ALU\n - ALU3/BRU1: ALU, BRU\n - AGU0 (256 bits): store address, load\n - AGU1 (256 bits): store address, load\n - AGU2: store address\n - FP0 (256 bits): VPU\n - FP1 (256 bits): VPU\n - FP2 (256 bits): VPU, FP store data\n - FP3 (256 bits): VPU, DIV/SQRT\n\nCycles executing div or sqrt instructions: NA\nCycles loading/storing data              : 1.00\n"
                },
                {
                  "title": "Cycles summary",
                  "txt": "Front-end : 0.33\nDispatch  : 1.00\nOverall L1: 1.00\n"
                },
                {
                  "title": "Vectorization ratios",
                  "txt": "all     : 0%\nload    : NA (no load vectorizable/vectorized instructions)\nstore   : 0%\nmul     : NA (no mul vectorizable/vectorized instructions)\nadd-sub : NA (no add-sub vectorizable/vectorized instructions)\nfma     : NA (no fma vectorizable/vectorized instructions)\ndiv/sqrt: NA (no div/sqrt vectorizable/vectorized instructions)\nother   : NA (no other vectorizable/vectorized instructions)\n"
                },
                {
                  "title": "Vector efficiency ratios",
                  "txt": "all     : 25%\nload    : NA (no load vectorizable/vectorized instructions)\nstore   : 25%\nmul     : NA (no mul vectorizable/vectorized instructions)\nadd-sub : NA (no add-sub vectorizable/vectorized instructions)\nfma     : NA (no fma vectorizable/vectorized instructions)\ndiv/sqrt: NA (no div/sqrt vectorizable/vectorized instructions)\nother   : NA (no other vectorizable/vectorized instructions)\n"
                },
                {
                  "title": "Cycles and memory resources usage",
                  "txt": "Assuming all data fit into the L1 cache, each call to the function takes 1.00 cycles. At this rate:\n - 25% of peak store performance is reached (8.00 out of 32.00 bytes stored per cycle (GB/s @ 1GHz))\n"
                },
                {
                  "title": "Front-end bottlenecks",
                  "txt": "Found no such bottlenecks."
                },
                {
                  "title": "ASM code",
                  "txt": "In the binary file, the address of the function is: 3bf40\n\nInstruction             | Nb FU | ALU0/BRU0 | ALU1 | ALU2 | ALU3/BRU1 | AGU0 | AGU1 | AGU2 | FP0 | FP1 | FP2 | FP3 | Latency | Recip. throughput | Vectorization\n----------------------------------------------------------------------------------------------------------------------------------------------------------------\nVMOVSD %XMM0,0x10(%RDI) | 1     | 0         | 0    | 0    | 0         | 0.33 | 0.33 | 0.33 | 0   | 0   | 1   | 0   | 1       | 1                 | scal (25.0%)\nRET                     | 1     | 0.50      | 0    | 0    | 0.50      | 0    | 0    | 0    | 0   | 0   | 0   | 0   | 1       | 0.50              | N/A\n"
                }
              ],
            "header":
              [
              "0% of peak computational performance is used (0.00 out of 48.00 FLOP per cycle (GFLOPS @ 1GHz))"
              ],
            "brief":
              [

              ],
            "gain":
              [
                {
                  "workaround": " - Try another compiler or update/tune your current one\n - Make array accesses unit-stride:\n  * If your function streams arrays of structures (AoS), try to use structures of arrays instead (SoA):\nfor(i) a[i].x = b[i].x; (slow, non stride 1) => for(i) a.x[i] = b.x[i]; (fast, stride 1)\n",
                  "details": "All SSE/AVX instructions are used in scalar version (process only one data element in vector registers).\nSince your execution units are vector units, only a vectorized function can use their full power.\n",
                  "title": "Vectorization",
                  "txt": "Your function is not vectorized.\n4 data elements could be processed at once in vector registers.\nBy vectorizing your function, you can lower the cost of an iteration from 1.00 to 0.25 cycles (4.00x speedup)."
                },
                {
                  "title": "Execution units bottlenecks",
                  "txt": "Found no such bottlenecks but see expert reports for more complex bottlenecks."
                }
              ],
            "potential":
              [

              ]
          }
        ],
      "common":
        {
          "header":
            [
            "The function is defined in /home/corentin/Documents/Cours/M2/CHPS0901/Projet_CHPS0901/sources/particle.cpp:34-35.\n"
            ],
          "nb_paths": 1
        }
    }
}
