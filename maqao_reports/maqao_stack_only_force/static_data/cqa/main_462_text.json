{
  "_cqa_text_report":
    {
      "_objects":
        {
          "image_vec_align":
            {
              "type": "image",
              "format": "url",
              "data": "../images/cqa/vec_align.svg",
              "size":
                {
                  "x": 500
                }
            },
          "image_1x64_512":
            {
              "type": "image",
              "format": "url",
              "data": "../images/cqa/1x64_512.svg",
              "size":
                {
                  "x": 500
                }
            },
          "image_1x32_128":
            {
              "type": "image",
              "format": "url",
              "data": "../images/cqa/1x32_128.svg",
              "size":
                {
                  "x": 500
                }
            },
          "image_4x32_256":
            {
              "type": "image",
              "format": "url",
              "data": "../images/cqa/4x32_256.svg",
              "size":
                {
                  "x": 500
                }
            },
          "image_1x64_128":
            {
              "type": "image",
              "format": "url",
              "data": "../images/cqa/1x64_128.svg",
              "size":
                {
                  "x": 500
                }
            },
          "image_2x64_256":
            {
              "type": "image",
              "format": "url",
              "data": "../images/cqa/2x64_256.svg",
              "size":
                {
                  "x": 500
                }
            },
          "image_4x32_512":
            {
              "type": "image",
              "format": "url",
              "data": "../images/cqa/4x32_512.svg",
              "size":
                {
                  "x": 500
                }
            },
          "image_8x32_512":
            {
              "type": "image",
              "format": "url",
              "data": "../images/cqa/8x32_512.svg",
              "size":
                {
                  "x": 500
                }
            },
          "image_1x32_256":
            {
              "type": "image",
              "format": "url",
              "data": "../images/cqa/1x32_256.svg",
              "size":
                {
                  "x": 500
                }
            },
          "image_2x64_512":
            {
              "type": "image",
              "format": "url",
              "data": "../images/cqa/2x64_512.svg",
              "size":
                {
                  "x": 500
                }
            },
          "image_1x32_512":
            {
              "type": "image",
              "format": "url",
              "data": "../images/cqa/1x32_512.svg",
              "size":
                {
                  "x": 500
                }
            },
          "image_1x64_256":
            {
              "type": "image",
              "format": "url",
              "data": "../images/cqa/1x64_256.svg",
              "size":
                {
                  "x": 500
                }
            },
          "image_4x64_512":
            {
              "type": "image",
              "format": "url",
              "data": "../images/cqa/4x64_512.svg",
              "size":
                {
                  "x": 500
                }
            },
          "image_row_maj":
            {
              "type": "image",
              "format": "url",
              "data": "../images/cqa/row_maj.svg",
              "size":
                {
                  "x": 500
                }
            },
          "image_col_maj":
            {
              "type": "image",
              "format": "url",
              "data": "../images/cqa/col_maj.svg",
              "size":
                {
                  "x": 500
                }
            },
          "list_path_1_vec_align_1":
            {
              "dynamic": true,
              "initial": "closed",
              "type": "list",
              "lines":
                [
                "/home/corentin/Documents/Cours/M2/CHPS0901/Projet_CHPS0901/sources/quadtree.cpp:277",
                "/home/corentin/Documents/Cours/M2/CHPS0901/Projet_CHPS0901/sources/quadtree.cpp:277",
                "/home/corentin/Documents/Cours/M2/CHPS0901/Projet_CHPS0901/sources/quadtree.cpp:277",
                "/home/corentin/Documents/Cours/M2/CHPS0901/Projet_CHPS0901/sources/quadtree.cpp:277",
                "/home/corentin/Documents/Cours/M2/CHPS0901/Projet_CHPS0901/sources/quadtree.cpp:277",
                "/home/corentin/Documents/Cours/M2/CHPS0901/Projet_CHPS0901/sources/quadtree.cpp:277",
                "/home/corentin/Documents/Cours/M2/CHPS0901/Projet_CHPS0901/sources/quadtree.cpp:277",
                "/home/corentin/Documents/Cours/M2/CHPS0901/Projet_CHPS0901/sources/quadtree.cpp:277",
                "/home/corentin/Documents/Cours/M2/CHPS0901/Projet_CHPS0901/sources/quadtree.cpp:277",
                "/home/corentin/Documents/Cours/M2/CHPS0901/Projet_CHPS0901/sources/quadtree.cpp:277",
                "/home/corentin/Documents/Cours/M2/CHPS0901/Projet_CHPS0901/sources/quadtree.cpp:277",
                "/home/corentin/Documents/Cours/M2/CHPS0901/Projet_CHPS0901/sources/quadtree.cpp:277",
                "/home/corentin/Documents/Cours/M2/CHPS0901/Projet_CHPS0901/sources/quadtree.cpp:277",
                "/home/corentin/Documents/Cours/M2/CHPS0901/Projet_CHPS0901/sources/quadtree.cpp:277",
                "/home/corentin/Documents/Cours/M2/CHPS0901/Projet_CHPS0901/sources/quadtree.cpp:277",
                "/home/corentin/Documents/Cours/M2/CHPS0901/Projet_CHPS0901/sources/quadtree.cpp:277"
                ],
              "header": ""
            }
        },
      "AVG":
        {
          "hint":
            [
              {
                "workaround": "Use vector aligned instructions:\n 1) align your arrays on 32 bytes boundaries: replace { void *p = malloc (size); } with { void *p; posix_memalign (&p, 32, size); }.\n 2) inform your compiler that your arrays are vector aligned: if array 'foo' is 32 bytes-aligned, define a pointer 'p_foo' as __builtin_assume_aligned (foo, 32) and use it instead of 'foo' in the loop.\n<<image_vec_align>>",
                "details": " - VMOVUPD: 16 occurrences<<list_path_1_vec_align_1>>\n",
                "title": "Vector unaligned load/store instructions",
                "txt": "Detected 16 optimal vector unaligned load/store instructions.\n"
              },
              {
                "title": "Type of elements and instruction set",
                "txt": "8 AVX instructions are processing arithmetic or math operations on double precision FP elements in vector mode (four at a time).\n"
              },
              {
                "title": "Matching between your loop (in the source code) and the binary loop",
                "txt": "The binary loop is composed of 32 FP arithmetical operations:\n - 32: addition or subtraction\nThe binary loop is loading 512 bytes (64 double precision FP elements).\nThe binary loop is storing 256 bytes (32 double precision FP elements)."
              },
              {
                "title": "Arithmetic intensity",
                "txt": "Arithmetic intensity is 0.04 FP operations per loaded or stored byte."
              }
            ],
          "expert":
            [
              {
                "title": "General properties",
                "txt": "nb instructions    : 28\nnb uops            : 27\nloop length        : 214\nused x86 registers : 5\nused mmx registers : 0\nused xmm registers : 0\nused ymm registers : 16\nused zmm registers : 0\nnb stack references: 0\n"
              },
              {
                "title": "Front-end",
                "txt": "ASSUMED MACRO FUSION\nFIT IN UOP CACHE\nmicro-operation queue: 4.50 cycles\nfront end            : 4.50 cycles\n"
              },
              {
                "title": "Back-end",
                "txt": "       | ALU0/BRU0 | ALU1 | ALU2 | ALU3/BRU1 | AGU0 | AGU1 | AGU2 | FP0  | FP1  | FP2  | FP3\n---------------------------------------------------------------------------------------------\nuops   | 0.75      | 0.75 | 0.75 | 0.75      | 8.00 | 8.00 | 8.00 | 0.00 | 0.00 | 8.00 | 8.00\ncycles | 0.75      | 0.75 | 0.75 | 0.75      | 8.00 | 8.00 | 8.00 | 0.00 | 0.00 | 8.00 | 8.00\n\nExecution ports to units layout:\n - ALU0/BRU0: ALU, BRU\n - ALU1: ALU\n - ALU2: ALU\n - ALU3/BRU1: ALU, BRU\n - AGU0 (256 bits): store address, load\n - AGU1 (256 bits): store address, load\n - AGU2: store address\n - FP0 (256 bits): VPU\n - FP1 (256 bits): VPU\n - FP2 (256 bits): VPU, FP store data\n - FP3 (256 bits): VPU, DIV/SQRT\n\nCycles executing div or sqrt instructions: NA\nCycles loading/storing data              : 8.00\nLongest recurrence chain latency (RecMII): 1.00\n"
              },
              {
                "title": "Cycles summary",
                "txt": "Front-end : 4.50\nDispatch  : 8.00\nData deps.: 1.00\nOverall L1: 8.00\n"
              },
              {
                "title": "Vectorization ratios",
                "txt": "all     : 100%\nload    : 100%\nstore   : 100%\nmul     : NA (no mul vectorizable/vectorized instructions)\nadd-sub : 100%\nfma     : NA (no fma vectorizable/vectorized instructions)\ndiv/sqrt: NA (no div/sqrt vectorizable/vectorized instructions)\nother   : NA (no other vectorizable/vectorized instructions)\n"
              },
              {
                "title": "Vector efficiency ratios",
                "txt": "all     : 100%\nload    : 100%\nstore   : 100%\nmul     : NA (no mul vectorizable/vectorized instructions)\nadd-sub : 100%\nfma     : NA (no fma vectorizable/vectorized instructions)\ndiv/sqrt: NA (no div/sqrt vectorizable/vectorized instructions)\nother   : NA (no other vectorizable/vectorized instructions)\n"
              },
              {
                "title": "Cycles and memory resources usage",
                "txt": "Assuming all data fit into the L1 cache, each iteration of the binary loop takes 8.00 cycles. At this rate:\n - 100% of peak load performance is reached (64.00 out of 64.00 bytes loaded per cycle (GB/s @ 1GHz))\n - 100% of peak store performance is reached (32.00 out of 32.00 bytes stored per cycle (GB/s @ 1GHz))\n"
              },
              {
                "title": "Front-end bottlenecks",
                "txt": "Found no such bottlenecks."
              },
              {
                "title": "ASM code",
                "txt": "In the binary file, the address of the loop is: 430a7\n\nInstruction                                                | Nb FU | ALU0/BRU0 | ALU1 | ALU2 | ALU3/BRU1 | AGU0 | AGU1 | AGU2 | FP0 | FP1 | FP2  | FP3  | Latency | Recip. throughput | Vectorization\n-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\nVMOVUPD (%RBX,%RAX,1),%YMM14                               | 1     | 0         | 0    | 0    | 0         | 0.50 | 0.50 | 0    | 0   | 0   | 0    | 0    | 3       | 0.50              | vect (100.0%)\nADD $0x8,%RDX                                              | 1     | 0.25      | 0.25 | 0.25 | 0.25      | 0    | 0    | 0    | 0   | 0   | 0    | 0    | 1       | 0.25              | N/A\nVMOVUPD 0x20(%RBX,%RAX,1),%YMM0                            | 1     | 0         | 0    | 0    | 0         | 0.50 | 0.50 | 0    | 0   | 0   | 0    | 0    | 3       | 0.50              | vect (100.0%)\nVMOVUPD 0x40(%RBX,%RAX,1),%YMM2                            | 1     | 0         | 0    | 0    | 0         | 0.50 | 0.50 | 0    | 0   | 0   | 0    | 0    | 3       | 0.50              | vect (100.0%)\nVMOVUPD 0x60(%RBX,%RAX,1),%YMM4                            | 1     | 0         | 0    | 0    | 0         | 0.50 | 0.50 | 0    | 0   | 0   | 0    | 0    | 3       | 0.50              | vect (100.0%)\nVMOVUPD 0x80(%RBX,%RAX,1),%YMM6                            | 1     | 0         | 0    | 0    | 0         | 0.50 | 0.50 | 0    | 0   | 0   | 0    | 0    | 3       | 0.50              | vect (100.0%)\nVMOVUPD 0xa0(%RBX,%RAX,1),%YMM8                            | 1     | 0         | 0    | 0    | 0         | 0.50 | 0.50 | 0    | 0   | 0   | 0    | 0    | 3       | 0.50              | vect (100.0%)\nVMOVUPD 0xc0(%RBX,%RAX,1),%YMM10                           | 1     | 0         | 0    | 0    | 0         | 0.50 | 0.50 | 0    | 0   | 0   | 0    | 0    | 3       | 0.50              | vect (100.0%)\nVMOVUPD 0xe0(%RBX,%RAX,1),%YMM12                           | 1     | 0         | 0    | 0    | 0         | 0.50 | 0.50 | 0    | 0   | 0   | 0    | 0    | 3       | 0.50              | vect (100.0%)\nVADDPD (%R13,%RAX,1),%YMM14,%YMM15                         | 1     | 0         | 0    | 0    | 0         | 0.50 | 0.50 | 0    | 0   | 0   | 0.50 | 0.50 | 3       | 0.50              | vect (100.0%)\nVADDPD 0x20(%R13,%RAX,1),%YMM0,%YMM1                       | 1     | 0         | 0    | 0    | 0         | 0.50 | 0.50 | 0    | 0   | 0   | 0.50 | 0.50 | 3       | 0.50              | vect (100.0%)\nVADDPD 0x40(%R13,%RAX,1),%YMM2,%YMM3                       | 1     | 0         | 0    | 0    | 0         | 0.50 | 0.50 | 0    | 0   | 0   | 0.50 | 0.50 | 3       | 0.50              | vect (100.0%)\nVADDPD 0x60(%R13,%RAX,1),%YMM4,%YMM5                       | 1     | 0         | 0    | 0    | 0         | 0.50 | 0.50 | 0    | 0   | 0   | 0.50 | 0.50 | 3       | 0.50              | vect (100.0%)\nVADDPD 0x80(%R13,%RAX,1),%YMM6,%YMM7                       | 1     | 0         | 0    | 0    | 0         | 0.50 | 0.50 | 0    | 0   | 0   | 0.50 | 0.50 | 3       | 0.50              | vect (100.0%)\nVADDPD 0xa0(%R13,%RAX,1),%YMM8,%YMM9                       | 1     | 0         | 0    | 0    | 0         | 0.50 | 0.50 | 0    | 0   | 0   | 0.50 | 0.50 | 3       | 0.50              | vect (100.0%)\nVADDPD 0xc0(%R13,%RAX,1),%YMM10,%YMM11                     | 1     | 0         | 0    | 0    | 0         | 0.50 | 0.50 | 0    | 0   | 0   | 0.50 | 0.50 | 3       | 0.50              | vect (100.0%)\nVADDPD 0xe0(%R13,%RAX,1),%YMM12,%YMM13                     | 1     | 0         | 0    | 0    | 0         | 0.50 | 0.50 | 0    | 0   | 0   | 0.50 | 0.50 | 3       | 0.50              | vect (100.0%)\nVMOVUPD %YMM15,(%R13,%RAX,1)                               | 1     | 0         | 0    | 0    | 0         | 0.33 | 0.33 | 0.33 | 0   | 0   | 1    | 0    | 4       | 1                 | vect (100.0%)\nVMOVUPD %YMM1,0x20(%R13,%RAX,1)                            | 1     | 0         | 0    | 0    | 0         | 0.33 | 0.33 | 0.33 | 0   | 0   | 1    | 0    | 4       | 1                 | vect (100.0%)\nVMOVUPD %YMM3,0x40(%R13,%RAX,1)                            | 1     | 0         | 0    | 0    | 0         | 0.33 | 0.33 | 0.33 | 0   | 0   | 1    | 0    | 4       | 1                 | vect (100.0%)\nVMOVUPD %YMM5,0x60(%R13,%RAX,1)                            | 1     | 0         | 0    | 0    | 0         | 0.33 | 0.33 | 0.33 | 0   | 0   | 1    | 0    | 4       | 1                 | vect (100.0%)\nVMOVUPD %YMM7,0x80(%R13,%RAX,1)                            | 1     | 0         | 0    | 0    | 0         | 0.33 | 0.33 | 0.33 | 0   | 0   | 1    | 0    | 4       | 1                 | vect (100.0%)\nVMOVUPD %YMM9,0xa0(%R13,%RAX,1)                            | 1     | 0         | 0    | 0    | 0         | 0.33 | 0.33 | 0.33 | 0   | 0   | 1    | 0    | 4       | 1                 | vect (100.0%)\nVMOVUPD %YMM11,0xc0(%R13,%RAX,1)                           | 1     | 0         | 0    | 0    | 0         | 0.33 | 0.33 | 0.33 | 0   | 0   | 1    | 0    | 4       | 1                 | vect (100.0%)\nVMOVUPD %YMM13,0xe0(%R13,%RAX,1)                           | 1     | 0         | 0    | 0    | 0         | 0.33 | 0.33 | 0.33 | 0   | 0   | 1    | 0    | 4       | 1                 | vect (100.0%)\nADD $0x100,%RAX                                            | 1     | 0.25      | 0.25 | 0.25 | 0.25      | 0    | 0    | 0    | 0   | 0   | 0    | 0    | 1       | 0.25              | N/A\nCMP %RSI,%RDX                                              | 1     | 0.25      | 0.25 | 0.25 | 0.25      | 0    | 0    | 0    | 0   | 0   | 0    | 0    | 1       | 0.25              | N/A\nJB 430a7 <_ZN8QuadTree15updateParticlesEd._omp_fn.1+0x857> | 1     | 0.50      | 0    | 0    | 0.50      | 0    | 0    | 0    | 0   | 0   | 0    | 0    | 1       | 0.50              | N/A\n"
              }
            ],
          "header":
            [
            "16% of peak computational performance is used (4.00 out of 24.00 FLOP per cycle (GFLOPS @ 1GHz))"
            ],
          "brief":
            [

            ],
          "gain":
            [
              {
                "details": "All SSE/AVX instructions are used in vector version (process two or more data elements in vector registers).\n",
                "title": "Vectorization",
                "txt": "Your loop is fully vectorized, using full register length.\n"
              },
              {
                "workaround": " - Reduce the number of FP add instructions\n - Read less array elements\nAll SSE and/or AVX registers are used:\nin that case, try to relax register pressure by reducing the unroll factor or splitting your loop\n - Write less array elements\n - Provide more information to your compiler:\n  * hardcode the bounds of the corresponding 'for' loop\n",
                "title": "Execution units bottlenecks",
                "txt": "Performance is limited by:\n - execution of FP add operations (the FP add unit is a bottleneck)\n - reading data from caches/RAM (load units are a bottleneck)\n - writing data to caches/RAM (the store unit is a bottleneck)\n\nBy removing all these bottlenecks, you can lower the cost of an iteration from 8.00 to 4.50 cycles (1.78x speedup).\n"
              }
            ],
          "potential":
            [

            ]
        },
      "paths":
        [
          {
            "hint":
              [
                {
                  "workaround": "Use vector aligned instructions:\n 1) align your arrays on 32 bytes boundaries: replace { void *p = malloc (size); } with { void *p; posix_memalign (&p, 32, size); }.\n 2) inform your compiler that your arrays are vector aligned: if array 'foo' is 32 bytes-aligned, define a pointer 'p_foo' as __builtin_assume_aligned (foo, 32) and use it instead of 'foo' in the loop.\n<<image_vec_align>>",
                  "details": " - VMOVUPD: 16 occurrences<<list_path_1_vec_align_1>>\n",
                  "title": "Vector unaligned load/store instructions",
                  "txt": "Detected 16 optimal vector unaligned load/store instructions.\n"
                },
                {
                  "title": "Type of elements and instruction set",
                  "txt": "8 AVX instructions are processing arithmetic or math operations on double precision FP elements in vector mode (four at a time).\n"
                },
                {
                  "title": "Matching between your loop (in the source code) and the binary loop",
                  "txt": "The binary loop is composed of 32 FP arithmetical operations:\n - 32: addition or subtraction\nThe binary loop is loading 512 bytes (64 double precision FP elements).\nThe binary loop is storing 256 bytes (32 double precision FP elements)."
                },
                {
                  "title": "Arithmetic intensity",
                  "txt": "Arithmetic intensity is 0.04 FP operations per loaded or stored byte."
                }
              ],
            "expert":
              [
                {
                  "title": "General properties",
                  "txt": "nb instructions    : 28\nnb uops            : 27\nloop length        : 214\nused x86 registers : 5\nused mmx registers : 0\nused xmm registers : 0\nused ymm registers : 16\nused zmm registers : 0\nnb stack references: 0\n"
                },
                {
                  "title": "Front-end",
                  "txt": "ASSUMED MACRO FUSION\nFIT IN UOP CACHE\nmicro-operation queue: 4.50 cycles\nfront end            : 4.50 cycles\n"
                },
                {
                  "title": "Back-end",
                  "txt": "       | ALU0/BRU0 | ALU1 | ALU2 | ALU3/BRU1 | AGU0 | AGU1 | AGU2 | FP0  | FP1  | FP2  | FP3\n---------------------------------------------------------------------------------------------\nuops   | 0.75      | 0.75 | 0.75 | 0.75      | 8.00 | 8.00 | 8.00 | 0.00 | 0.00 | 8.00 | 8.00\ncycles | 0.75      | 0.75 | 0.75 | 0.75      | 8.00 | 8.00 | 8.00 | 0.00 | 0.00 | 8.00 | 8.00\n\nExecution ports to units layout:\n - ALU0/BRU0: ALU, BRU\n - ALU1: ALU\n - ALU2: ALU\n - ALU3/BRU1: ALU, BRU\n - AGU0 (256 bits): store address, load\n - AGU1 (256 bits): store address, load\n - AGU2: store address\n - FP0 (256 bits): VPU\n - FP1 (256 bits): VPU\n - FP2 (256 bits): VPU, FP store data\n - FP3 (256 bits): VPU, DIV/SQRT\n\nCycles executing div or sqrt instructions: NA\nCycles loading/storing data              : 8.00\nLongest recurrence chain latency (RecMII): 1.00\n"
                },
                {
                  "title": "Cycles summary",
                  "txt": "Front-end : 4.50\nDispatch  : 8.00\nData deps.: 1.00\nOverall L1: 8.00\n"
                },
                {
                  "title": "Vectorization ratios",
                  "txt": "all     : 100%\nload    : 100%\nstore   : 100%\nmul     : NA (no mul vectorizable/vectorized instructions)\nadd-sub : 100%\nfma     : NA (no fma vectorizable/vectorized instructions)\ndiv/sqrt: NA (no div/sqrt vectorizable/vectorized instructions)\nother   : NA (no other vectorizable/vectorized instructions)\n"
                },
                {
                  "title": "Vector efficiency ratios",
                  "txt": "all     : 100%\nload    : 100%\nstore   : 100%\nmul     : NA (no mul vectorizable/vectorized instructions)\nadd-sub : 100%\nfma     : NA (no fma vectorizable/vectorized instructions)\ndiv/sqrt: NA (no div/sqrt vectorizable/vectorized instructions)\nother   : NA (no other vectorizable/vectorized instructions)\n"
                },
                {
                  "title": "Cycles and memory resources usage",
                  "txt": "Assuming all data fit into the L1 cache, each iteration of the binary loop takes 8.00 cycles. At this rate:\n - 100% of peak load performance is reached (64.00 out of 64.00 bytes loaded per cycle (GB/s @ 1GHz))\n - 100% of peak store performance is reached (32.00 out of 32.00 bytes stored per cycle (GB/s @ 1GHz))\n"
                },
                {
                  "title": "Front-end bottlenecks",
                  "txt": "Found no such bottlenecks."
                },
                {
                  "title": "ASM code",
                  "txt": "In the binary file, the address of the loop is: 430a7\n\nInstruction                                                | Nb FU | ALU0/BRU0 | ALU1 | ALU2 | ALU3/BRU1 | AGU0 | AGU1 | AGU2 | FP0 | FP1 | FP2  | FP3  | Latency | Recip. throughput | Vectorization\n-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\nVMOVUPD (%RBX,%RAX,1),%YMM14                               | 1     | 0         | 0    | 0    | 0         | 0.50 | 0.50 | 0    | 0   | 0   | 0    | 0    | 3       | 0.50              | vect (100.0%)\nADD $0x8,%RDX                                              | 1     | 0.25      | 0.25 | 0.25 | 0.25      | 0    | 0    | 0    | 0   | 0   | 0    | 0    | 1       | 0.25              | N/A\nVMOVUPD 0x20(%RBX,%RAX,1),%YMM0                            | 1     | 0         | 0    | 0    | 0         | 0.50 | 0.50 | 0    | 0   | 0   | 0    | 0    | 3       | 0.50              | vect (100.0%)\nVMOVUPD 0x40(%RBX,%RAX,1),%YMM2                            | 1     | 0         | 0    | 0    | 0         | 0.50 | 0.50 | 0    | 0   | 0   | 0    | 0    | 3       | 0.50              | vect (100.0%)\nVMOVUPD 0x60(%RBX,%RAX,1),%YMM4                            | 1     | 0         | 0    | 0    | 0         | 0.50 | 0.50 | 0    | 0   | 0   | 0    | 0    | 3       | 0.50              | vect (100.0%)\nVMOVUPD 0x80(%RBX,%RAX,1),%YMM6                            | 1     | 0         | 0    | 0    | 0         | 0.50 | 0.50 | 0    | 0   | 0   | 0    | 0    | 3       | 0.50              | vect (100.0%)\nVMOVUPD 0xa0(%RBX,%RAX,1),%YMM8                            | 1     | 0         | 0    | 0    | 0         | 0.50 | 0.50 | 0    | 0   | 0   | 0    | 0    | 3       | 0.50              | vect (100.0%)\nVMOVUPD 0xc0(%RBX,%RAX,1),%YMM10                           | 1     | 0         | 0    | 0    | 0         | 0.50 | 0.50 | 0    | 0   | 0   | 0    | 0    | 3       | 0.50              | vect (100.0%)\nVMOVUPD 0xe0(%RBX,%RAX,1),%YMM12                           | 1     | 0         | 0    | 0    | 0         | 0.50 | 0.50 | 0    | 0   | 0   | 0    | 0    | 3       | 0.50              | vect (100.0%)\nVADDPD (%R13,%RAX,1),%YMM14,%YMM15                         | 1     | 0         | 0    | 0    | 0         | 0.50 | 0.50 | 0    | 0   | 0   | 0.50 | 0.50 | 3       | 0.50              | vect (100.0%)\nVADDPD 0x20(%R13,%RAX,1),%YMM0,%YMM1                       | 1     | 0         | 0    | 0    | 0         | 0.50 | 0.50 | 0    | 0   | 0   | 0.50 | 0.50 | 3       | 0.50              | vect (100.0%)\nVADDPD 0x40(%R13,%RAX,1),%YMM2,%YMM3                       | 1     | 0         | 0    | 0    | 0         | 0.50 | 0.50 | 0    | 0   | 0   | 0.50 | 0.50 | 3       | 0.50              | vect (100.0%)\nVADDPD 0x60(%R13,%RAX,1),%YMM4,%YMM5                       | 1     | 0         | 0    | 0    | 0         | 0.50 | 0.50 | 0    | 0   | 0   | 0.50 | 0.50 | 3       | 0.50              | vect (100.0%)\nVADDPD 0x80(%R13,%RAX,1),%YMM6,%YMM7                       | 1     | 0         | 0    | 0    | 0         | 0.50 | 0.50 | 0    | 0   | 0   | 0.50 | 0.50 | 3       | 0.50              | vect (100.0%)\nVADDPD 0xa0(%R13,%RAX,1),%YMM8,%YMM9                       | 1     | 0         | 0    | 0    | 0         | 0.50 | 0.50 | 0    | 0   | 0   | 0.50 | 0.50 | 3       | 0.50              | vect (100.0%)\nVADDPD 0xc0(%R13,%RAX,1),%YMM10,%YMM11                     | 1     | 0         | 0    | 0    | 0         | 0.50 | 0.50 | 0    | 0   | 0   | 0.50 | 0.50 | 3       | 0.50              | vect (100.0%)\nVADDPD 0xe0(%R13,%RAX,1),%YMM12,%YMM13                     | 1     | 0         | 0    | 0    | 0         | 0.50 | 0.50 | 0    | 0   | 0   | 0.50 | 0.50 | 3       | 0.50              | vect (100.0%)\nVMOVUPD %YMM15,(%R13,%RAX,1)                               | 1     | 0         | 0    | 0    | 0         | 0.33 | 0.33 | 0.33 | 0   | 0   | 1    | 0    | 4       | 1                 | vect (100.0%)\nVMOVUPD %YMM1,0x20(%R13,%RAX,1)                            | 1     | 0         | 0    | 0    | 0         | 0.33 | 0.33 | 0.33 | 0   | 0   | 1    | 0    | 4       | 1                 | vect (100.0%)\nVMOVUPD %YMM3,0x40(%R13,%RAX,1)                            | 1     | 0         | 0    | 0    | 0         | 0.33 | 0.33 | 0.33 | 0   | 0   | 1    | 0    | 4       | 1                 | vect (100.0%)\nVMOVUPD %YMM5,0x60(%R13,%RAX,1)                            | 1     | 0         | 0    | 0    | 0         | 0.33 | 0.33 | 0.33 | 0   | 0   | 1    | 0    | 4       | 1                 | vect (100.0%)\nVMOVUPD %YMM7,0x80(%R13,%RAX,1)                            | 1     | 0         | 0    | 0    | 0         | 0.33 | 0.33 | 0.33 | 0   | 0   | 1    | 0    | 4       | 1                 | vect (100.0%)\nVMOVUPD %YMM9,0xa0(%R13,%RAX,1)                            | 1     | 0         | 0    | 0    | 0         | 0.33 | 0.33 | 0.33 | 0   | 0   | 1    | 0    | 4       | 1                 | vect (100.0%)\nVMOVUPD %YMM11,0xc0(%R13,%RAX,1)                           | 1     | 0         | 0    | 0    | 0         | 0.33 | 0.33 | 0.33 | 0   | 0   | 1    | 0    | 4       | 1                 | vect (100.0%)\nVMOVUPD %YMM13,0xe0(%R13,%RAX,1)                           | 1     | 0         | 0    | 0    | 0         | 0.33 | 0.33 | 0.33 | 0   | 0   | 1    | 0    | 4       | 1                 | vect (100.0%)\nADD $0x100,%RAX                                            | 1     | 0.25      | 0.25 | 0.25 | 0.25      | 0    | 0    | 0    | 0   | 0   | 0    | 0    | 1       | 0.25              | N/A\nCMP %RSI,%RDX                                              | 1     | 0.25      | 0.25 | 0.25 | 0.25      | 0    | 0    | 0    | 0   | 0   | 0    | 0    | 1       | 0.25              | N/A\nJB 430a7 <_ZN8QuadTree15updateParticlesEd._omp_fn.1+0x857> | 1     | 0.50      | 0    | 0    | 0.50      | 0    | 0    | 0    | 0   | 0   | 0    | 0    | 1       | 0.50              | N/A\n"
                }
              ],
            "header":
              [
              "16% of peak computational performance is used (4.00 out of 24.00 FLOP per cycle (GFLOPS @ 1GHz))"
              ],
            "brief":
              [

              ],
            "gain":
              [
                {
                  "details": "All SSE/AVX instructions are used in vector version (process two or more data elements in vector registers).\n",
                  "title": "Vectorization",
                  "txt": "Your loop is fully vectorized, using full register length.\n"
                },
                {
                  "workaround": " - Reduce the number of FP add instructions\n - Read less array elements\nAll SSE and/or AVX registers are used:\nin that case, try to relax register pressure by reducing the unroll factor or splitting your loop\n - Write less array elements\n - Provide more information to your compiler:\n  * hardcode the bounds of the corresponding 'for' loop\n",
                  "title": "Execution units bottlenecks",
                  "txt": "Performance is limited by:\n - execution of FP add operations (the FP add unit is a bottleneck)\n - reading data from caches/RAM (load units are a bottleneck)\n - writing data to caches/RAM (the store unit is a bottleneck)\n\nBy removing all these bottlenecks, you can lower the cost of an iteration from 8.00 to 4.50 cycles (1.78x speedup).\n"
                }
              ],
            "potential":
              [

              ]
          }
        ],
      "common":
        {
          "header":
            [
            "The loop is defined in /home/corentin/Documents/Cours/M2/CHPS0901/Projet_CHPS0901/sources/quadtree.cpp:277.\n",
            "It is main loop of related source loop which is unrolled by 4 (including vectorization)."
            ],
          "nb_paths": 1
        }
    }
}
