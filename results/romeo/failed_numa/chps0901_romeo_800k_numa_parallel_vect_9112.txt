Loading x86_64 (no gpu) environment
Environment loaded. Spack available.
========================================
Barnes-Hut MPI/OpenMP with recycle memory implementation
Generating 800000 particles
Particles received by rank 0
The simulation window size is 220000
Running simulation for 100 steps with a time step of 1s
Step (dt): 1s
Number of epochs compute: 100
Number of particles: 800000
Number of MPI processes: 1
Number of OpenMP threads: 1
Starting simulation with 800000 particles
Simulation time: 1703.83 seconds
Folder created
Particles status result saved to results/particle_output_1742918739.txt
End of Simulation with Barnes-Hut MPI/OpenMP with recycle memory implementation
========================================
========================================
Barnes-Hut MPI/OpenMP with recycle memory implementation
Generating 800000 particles
Particles received by rank 0
The simulation window size is 220000
Running simulation for 100 steps with a time step of 1s
Step (dt): 1s
Number of epochs compute: 100
Number of particles: 800000
Number of MPI processes: 1
Number of OpenMP threads: 2
Starting simulation with 800000 particles
Simulation time: 1707.18 seconds
Folder created
Particles status result saved to results/particle_output_1742920452.txt
End of Simulation with Barnes-Hut MPI/OpenMP with recycle memory implementation
========================================
========================================
Barnes-Hut MPI/OpenMP with recycle memory implementation
Generating 800000 particles
Particles received by rank 0
The simulation window size is 220000
Running simulation for 100 steps with a time step of 1s
Step (dt): 1s
Number of epochs compute: 100
Number of particles: 800000
Number of MPI processes: 1
Number of OpenMP threads: 3
Starting simulation with 800000 particles
Simulation time: 1707.78 seconds
Folder created
Particles status result saved to results/particle_output_1742922166.txt
End of Simulation with Barnes-Hut MPI/OpenMP with recycle memory implementation
========================================
========================================
Barnes-Hut MPI/OpenMP with recycle memory implementation
Generating 800000 particles
Particles received by rank 0
The simulation window size is 220000
Running simulation for 100 steps with a time step of 1s
Step (dt): 1s
Number of epochs compute: 100
Number of particles: 800000
Number of MPI processes: 1
Number of OpenMP threads: 4
Starting simulation with 800000 particles
Simulation time: 1702.64 seconds
Folder created
Particles status result saved to results/particle_output_1742923875.txt
End of Simulation with Barnes-Hut MPI/OpenMP with recycle memory implementation
========================================
========================================
Barnes-Hut MPI/OpenMP with recycle memory implementation
Generating 800000 particles
Particles received by rank 0
The simulation window size is 220000
Running simulation for 100 steps with a time step of 1s
Step (dt): 1s
Number of epochs compute: 100
Number of particles: 800000
Number of MPI processes: 1
Number of OpenMP threads: 5
Starting simulation with 800000 particles
Simulation time: 1710.78 seconds
Folder created
Particles status result saved to results/particle_output_1742925592.txt
End of Simulation with Barnes-Hut MPI/OpenMP with recycle memory implementation
========================================
========================================
Barnes-Hut MPI/OpenMP with recycle memory implementation
Generating 800000 particles
Particles received by rank 0
The simulation window size is 220000
Running simulation for 100 steps with a time step of 1s
Step (dt): 1s
Number of epochs compute: 100
Number of particles: 800000
Number of MPI processes: 1
Number of OpenMP threads: 6
Starting simulation with 800000 particles
slurmstepd: error: *** JOB 9112 ON romeo-c029 CANCELLED AT 2025-03-25T19:04:04 ***
--------------------------------------------------------------------------
ORTE has lost communication with a remote daemon.

  HNP daemon   : [[49879,0],0] on node romeo-c029
  Remote daemon: [[49879,0],1] on node romeo-c030

This is usually due to either a failure of the TCP network
connection to the node, or possibly an internal failure of
the daemon itself. We cannot recover from this failure, and
therefore will terminate the job.
--------------------------------------------------------------------------
